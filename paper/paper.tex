\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{array}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{wrapfig}
\title{A Systematic Approach to Analyzing Syndication of Viral News Stories}


\author{
 Gaurav Deshpande \\
  Institute for Software Research\\
  Carnegie Mellon University\\
  Pittsburgh, PA 15213 \\
  \texttt{gdeshpan@andrew.cmu.edu} \\
  %% examples of more authors
 \And
    Sam E. Teplov\\
    %\thanks{Use footnote for providing further
    %information about author (webpage, alternative
    %address)---\emph{not} for acknowledging funding agencies.} \\
  Institute for Software Research\\
  Carnegie Mellon University\\
  Pittsburgh, PA 15213 \\
  \texttt{steplov@andrew.cmu.edu} \\
 \And
   Alon Peer \\
  Department of Computer Science\\
  Carnegie Mellon University\\
  Pittsburgh, PA 15213 \\
  \texttt{apeer@andrew.cmu.edu} \\
 \AND
    Dr. Nicolas Christin \\
    Department of Computer Science \\
    Carnegie Mellon University\\
    Pittsburgh, PA 15213 \\
   \texttt{nicolasc@andrew.cmu.edu} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle

\begin{figure}[h]
    \centering
    \includegraphics[width=6.5cm]{paper/img/university.png}
\end{figure}

\begin{abstract}
In this work, we present a novel, semiautonomous methodology for analyzing syndicated news articles. We first detail our manual process of news syndication analysis from which we observe a number of unsettling patterns. From there, we go on to categorize and define two different forms of syndication: top-down and bottom-up. We then transform our manual process into a semiautomated one which combines web scraping and machine learning techniques to create and then analyze a data set of viral news stories. From the analysis, we are able to make some inferences about the nature of syndicated news articles, as well as trace back a viral news story to its original publisher and article. By presenting this work, we hope to minimize the effects that blind news syndication has on the spread of misinformation. 
\end{abstract}
\keywords{Fake news \and News propagation \and News syndication}
\newpage
\tableofcontents
\newpage
\section{Introduction}
Misinformation, disinformation, and fake news have become a common occurrence in our interconnected society. The idea of intentionally spreading fake news to sway public opinion, also known as disinformation, was brought to light by the U.S. Intelligence Committee's report on Russian meddling in the 2016 U.S. presidential election \cite{stelzenmuller2017impact}. Misinformation, or the unintentional spread of inaccurate news, has also become ubiquitous thanks to social media, which allows unreliable news to be proliferated quickly and without any verification \cite{pourghomi2017stop}. The use of a combination of misinformation and disinformation by nation states, non-state actors, and other politically motivated groups has become so prevalent that it has affected over seventy countries \cite{alba_satariano_2019}. This problem has gotten so extreme that the integrity of the U.S. election system, and even the fundamental democratic ideals of the U.S., have been called into question by some \cite{mueller2019report}. Due to the global nature of this problem, over fifty countries have begun to implement measures to combat misinformation and disinformation \cite{poynter}. The measures implemented by these countries span from laws and legislation, to creating task forces and launching official investigations to try to weed disinformation \cite{poynter}. Besides nation states trying to tackle this behemoth of a problem, many researchers and academics have also been trying to implement various methods to try to detect and classify misinformation, disinformation, and fake news. This area of research has become commonly known as \textit{fake news detection} \cite{zhang2019overview}. 

\subsection{Problem Statement}
There has already been many different approaches proposed to detecting and classifying fake news. Many proposed solutions have mostly relied on various machine learning techniques, such as using deep neural networks, or recurrent learning models \cite{shu2017fake}. These models for the most part work by training the model on a variety of features ranging anywhere from text-based features, to network features that show how the article has been spread through space and time \cite{shu2017fake}. The problem with these models is that they rely on a lot of information to be fed into them, which take a long time to extracted. Also, many of these approaches have only been tested on a few media outlets and social media platforms and could not work on a global scale.

One of the largest problems that has not be widely discussed or researched is that many media outlets simply take news articles from other news sources and republish them as their own. This process is known as news syndication. This is an extremely dangerous practice that can lead to the problem of fake news being further exacerbated. There are certain types of news syndication which are generally safe and do not lead to misinformation being spread. As we discuss later, other types of news syndication are dangerous and could easily be exploited by nation states seeking to carry out a disinformation campaign against another country. 

\subsection{Objectives}
Our first objective of this work is to build a system that given a viral article, could find related articles that were either syndicated off of the original article, or articles that were syndicated by the original article. This allows us to achieve our second objective of building a propagation path which shows where the original article was published, and by who. The third objective of this work is to then analyze the propagation path of the article and see what features change over time, how they change over time, and identify any patterns. 

The last two objectives of this work were not able to be accomplished in this research, but we hope they will be completed in future work. For one, we hope to eventually fully automate this process by incorporating various models for clickbait title identification, so that the clickbait model could feed our system articles to be analyzed. Our second future objective is to eventually incorporate existing fake news detection models so that once our system identifies the original article from the propagation path, it can then be classified as fake news or not. In the end, we hope to be able to provide the media consumer with a message stating where the article originated from, and if its veracity can be verified or not. 

\subsection{Contributions}
We make a number of contributions throughout this work. First, we present out initial manual methodology which outlines how we first identified viral articles, how we traced them back to their origin, and the findings from out analysis. From this analysis, we present and define two different types of news syndication: top-down and bottom-up. We then present a refined, semiautonomous methodology which is derived from our initial methodology, but with a few revisions. This methodology, given a viral news story and a couple related articles, will automatically scrape the web and identify articles within a set time window which were either syndicated from the original set of articles fed to it, or articles that the original set of articles syndicated. We use a combination and similarity score and key words that eventually feed into a dendrogram which clusters similar articles together. We then take this clustered data set and build a timeline which allows the original article to be identified. We also are able to perform a wide range of analysis on various article features and categorize how certain features change over time. This analysis then allows us to identify patterns about syndicated articles and eventually draw conclusions.

\subsection{Definitions}
The realm of fake news detection has become inundated with a variety of various terms that are used interchangeably depending on the article. It is important to define these various terms in order to avoid ambiguity and misunderstandings. The following definitions are taken from the Ethical Journalism Network \cite{ethicaljournalismnetwork}:  

\begin{itemize}
    \item \textbf{Fake News}: \textit{"Fake news is information deliberately fabricated and published with the intention to deceive and mislead others into believing falsehoods or doubting verifiable facts"}
    \item \textbf{Disinformation}: \textit{Information that is false and deliberately created to harm a person, social group, organization or country}.
    \item \textbf{Misinformation}: \textit{Information that is false, but not created with the intention of causing harm}.
    \item \textbf{Malinformation}: \textit{Information that is based on reality, used to inflict harm on a person, organization or country}.
\end{itemize}

The main difference between these definitions is the intent and what it is being used for. These terms may be used interchangeably in this work. This is because our work does not intend to differentiate between the intent of the news. Our work focuses on building a methodology that is able to semiautonomously trace back an article to its origin and analyze how article features change over time. Future work involves trying to classify news as fake or not, but that involves using already developed models for classification. Not even these models attempt to differentiate between different intentions. Therefore, although misinformation, disinformation, and fake news do technically have different meanings, they can be used interchangeably in this line of work since most research on fake news detection just attempts to classify news as accurate or inaccurate, not to try to determine the intent behind the article. 

\subsection{Limitations}
As stated before, this work does not attempt to make a determination of whether the content of an article is true or false. Instead, this research is primarily focused on presenting a semiautonomous methodology which can be used to identify the propagation path of a viral article, as well as conduct analysis on article features. In the future, we hope to full automate this methodology, as well as incorporate existing fake news classification models in order to actually make a determinate about content accuracy. However, for now, the scope of this work is strictly limited to semi autonomously identifying the propagation path of an article, as well as conducting time series analysis on articles features. 






%Fake news has been a real issue since the spark of social media, especially in the recent years, with its spike coming during the 2016 U.S. presidential election. In fact, a study from Ohio State University shows that fake news had a significant impact on the results of the elections. The researchers found a correlation between the amount of Obama voters who believed fake news about Clinton and the amount of them who chose to vote for Trump. At that time, the media was swarmed with fake news, and one could hardly blame people who couldn't distinguish them from real news.

%But what exactly is fake news? According to Wikipedia, "fake news is a form of news consisting of deliberate disinformation or hoaxes spread via traditional news media (print and broadcast) or online social media". In addition to this definition, fake news may also include clickbait stories, propaganda, satire, biased news, or even sometimes just bad journalism.

%These days, anyone can publish content on the internet, whether it is on a website, a blog, or a social media profile, and potentially reach large audiences. The fact that people nowadays rely on the internet to consume news doesn't make this problem any easier to solve.
%Fake news is very profitable for the publisher, as viral stories generate large amounts of traffic, thus increasing advertisement revenue. For that reason, fake news are widely common around the internet. 
%Another motive to publish fake news is to promote a political agenda. Fake political news stories are meant to persuade consumers to accept a biased of false beliefs (like the fake news regarding Hillary Clinton during the 2016 U.S. presidential election). This is the main reason detecting fake news is such a challenge. These false stories were created to sound true and interesting.

%A different variation of fake news is syndication. A website can take a real news story, and change it a bit, so it will fit that website's beliefs. A news story can be syndicated in various ways- changing the title, adding interpretations that aren't necessarily true, and much more. A popular form of syndication is news stories that are posted by local newspapers and websites, and as they get viral, these stories get picked up by bigger and more popular news websites. On the way from the local news source to the national (or international) news website, the story can get syndicated. Sometimes, it's not necessarily on purpose, but it happens due to the lack of due diligence by the mainstream media.

%One can try and detect fake news by checking the source of the story, read beyond the title (which is intended to attract users and thus contains more interesting and controversial topics), try to trace the article back to the original source, or even make sure the article is not a satire by any chance.
%Even though it's possible, doing so is not an easy task, and that is why there has been a lot of work put into automating this process. A step towards this, is detecting and analyzing the syndication of viral news stories. That is, how stories change through time and the difference between articles regrading the same stories but posted in different websites.

%The thing is, that identifying news propagation path is tedious, too. To identify the propagation path of a given article, one would have to dive deep into the results of Google search, manually identify the original source of the story, and look through many news websites and see the differences between the ways each website covers the same story. That's why we decided to try and automate this process using machine learning techniques and data analysis.
\section{Background}
The field of misinformation and fake news has become widely researched by academics ever since the Russian misinformation campaign against the 2016 United States presidential election came to light\cite{stelzenmuller2017impact}. The most straightforward approach to detecting fake news is applying various machine learning techniques, and this is what many researchers have focused on thus far.

\subsection{Fake News Detection}Shu et al. goes through a comprehensive overview of all of the various ways of attacking the problem of fake news detection and classification from a data mining perspective \cite{shu2017fake}. From the perspective of detecting fake news via machine learning techniques, Shu et al. outlines that there are generally four different types of features that can be used to detect fake news: news content features, linguistic-based features, visual-based features, and social context features. These features are then applied to one of two different types of models: news content models, or social context models . Just as they sound, news content models focus on fact checking claims in the news article or looking at stylistic features that may indicate that the article is fake. Social context models, on the other hand, focus on how users interact with the article, the virality of the article, and the propagation path of the news story. These two different methods are rarely used independently, but rather compliment each other in many hybrid approaches, such as ensemble models \cite{shu2017fake}. 

\subsection{Open Issues in Fake News Detection}
Shu et al. closes by giving an overview of many of the various open areas of research in this field, as well as proposing some future research ideas. Shu et al. outlines four future research directions: data-oriented, feature-oriented, model-oriented, and application-oriented. Within the area of data-oriented research, Shu et al. brings forward a couple of issues that need to be addressed. For one, there is no large, encompassing fake news data set which can be used as a benchmark to facilitate future research \cite{shu2017fake}. In fact, this was such a large problem that in 2018, Shu et al. published another work detailing their methodology for building a large scale, open source, data set consisting of fake news, which is now available on Github \cite{shu2018fakenewsnet}. Another idea that Shu et al. proposes for future research within the data-oriented direction is early fake news detection \cite{shu2017fake}. Many of the current state-of-the-art fake news detection methods rely on data that needs to be accumulated over time and information that is not readily available when news is just starting to go viral \cite{liu2018early}. Shu et al. suggests creating a system that provides fake news alerts during the dissemination process so that misinformation can be flagged before it is viewed by a large audience. Another suggestion that is made is to look at social media posts made within some time delay of the original posts as a means of verifying the veracity of the post \cite{shu2017fake}.  
%\label{sec:headings}

\section{Related Work}
There has been work done on early fake news detection by analyzing propagation paths and time series, as well as analyzing the dynamics of news syndication. Most of this work, however, has been limited in scope in terms of the domains that it covers, as well as the type of media being analyzed. For example, past research has focused on a either a few social media platforms, a specific media outlet, or a single country \cite{liu2018early},\cite{jin2014news}, \cite{wang2009propagation}. The research that has spanned across multiple different domains of news (social media, various news outlets, etc.) has been limited in scope when considering the type of media that is being analyzed \cite{zannettou2018origins}. There has been little work, if any, done specifically on the syndication of viral news and trying to automatically analyze and track back a viral news story to its original publisher.   

\subsection{Domain-Specific Approaches}
Liu et al. propose a method of early fake news detection by modeling the propagation paths as a multivariate time series. They build a classifier that uses recurrent and convolutional networks to detect fake news. They were able to achieve an accuracy of 85\% on Twitter and an accuracy of 92\% on Sina Weibo when it came to correctly classifying fake news. Liu et al. claims that they were able to detect the misinformation five minutes after it began to spread \cite{liu2018early}. The downside to this approach is that it relies on user interaction with the article to generate the data needed to feed into their classifier. This means that some users will be exposed to the fake news before it can be flagged as misinformation just due to the nature of the data set that they are using. Also, this approach has only been tested on social media platforms and micro blogs, meaning that this methodology cannot be applied on a global scale that spans hundreds of different news outlets and social media sites.

Jin et al., in their work, tackle the problem of misinformation on the popular website Micro blog. They propose a three-layer hierarchical model that establishes a credibility score for each post and then propagates this score throughout the network. They then formulate this propagation process as a graph optimization problem and find a globally optimal solution. Jin et al. were able to boost accuracy by 6\% over the baseline model \cite{jin2014news}. Again, just like Liu et al.'s approach, Jin et al. focus solely on one website: Micro blog. Their model is reliant on data to be taken specifically from Micro blog. Although their technique could in theory be applied to other platforms, their approach is mostly domain-specific and does not analyze misinformation on a global scale. 

Wang et al. explore and analyze the patterns of news propagation and syndication in Chinese news media. They draw comparisons between the way news diffuses through time and space and how an epidemic spreads. Something interesting that they found was that 80\% of news outlets were responsible for re-printing news articles directly from the source \cite{wang2009propagation}. Some of our findings also substantiate this claim. Like much of the other research on this topic, Wang et al. focused on only Chinese media outlets and they also did not attempt to trace back an article back to its original source without knowing what that source was in the first place. Although Wang et al.'s research brings to light some interesting patterns in the ways that news article propagate and are syndicated, the work is confined mostly to Chinese news media, which is known to be heavily regulated by the Chinese Communist Party \cite{tai2014china}.  


\subsection{Media-Specific Approaches}
Zannettou et al. take a different approach to analyzing propagation; instead of looking at social media posts or news stories, they focus on politically motivated memes. Unlike any of the previous research talked about, Zannettou et al. pool data from a number of various sources: Twitter, Reddit, 4chan, and Gab. Using memes from these sites, they are able to trace the propagation path of each meme and even draw conclusions about the influence that each meme outlet has. Zannettou et al. use Hawkes process to model how memes from various sources interact with each other and quantify the influence that each meme has on others \cite{zannettou2018origins}. Although this research encompasses many different media outlets and social media platforms, it fails to analyze any other form of media besides memes. Some of the processes outlined in this work could be applied to news articles, but much of it is very specific to memes and images and cannot be generalized to news articles due to the difference in data between an image and a set of text. Nevertheless, Zannettou et al. showed that memes are often syndicated by larger media outlets which causes fringe web communities to have a much broader reach than they ever could have before \cite{zannettou2018origins}. 




\section{Phase I - Manual Approach}
Our research and methodology can be split up into a manual process (phase I), and a semiautonomous process (phase II). In the manual approach, we created a data set of popular news articles and then attempted to trace them back to the original publisher. Once we identified the propagation path, we attempted to analyze how various article features changed over time.    

\subsection{Dataset Creation}
We started by collecting a diverse range of articles from a number of different news sources. As seen in Appendix \ref{appendix:a}, we selected five articles from each news source and recorded each articles' associated comment count. These articles were picked out between October 5 2019 and October 8 2019. We looked for articles that were published in the past two weeks. We picked media outlets that tended to be biased either towards the political left or right as defined by the chart in Appendix \ref{appendix:b}. The reason we did not pick any mainstream, unbiased news outlets (New York Times, Washington Post, Economist, etc.) is because these news sources typically do their due diligence in ensuring that the news that they are publishing is true, and the public typically trusts these sources \cite{kearney2017trusting}. It is also worth noting that we did not consider any articles that were about, or mentioned, President Donald Trump, as these could possibly skew results. Aside from that, we did not consider the actual content of the article when picking articles for the initial dataset. 

\subsection{Case Study: Chinese Gold}
One of the first articles that stuck out to us from the initial dataset was the article from the Daily Mail titled \textit{Thirteen and a half tonnes of gold worth up to £520million is found in a corrupt Chinese official’s home and £30BILLION in suspected bribe money in his bank account}. 

\begin{figure}[h]
    \centering
    \includegraphics[width=10cm]{paper/img/chinese-gold-dailymail.png}
    \caption {First Article About Chinese Gold That We Found}
    \label{fig:chinesegolddailymail}
\end{figure}

\subsubsection{Propagation Analysis}
The reason this article jumped out at us is because the number of comments for this article was much higher than any article in the dataset. Once we identified this specific story, we decided to try to trace it back to its original source. The process of trying to trace an article back to its origin is an extremely tedious and time consuming task. This is because there is no systematic approach already out there that can help us gather the information that we needed.  The data used to build the propagation path for the Chinese Gold Story can be found in Appendix \ref{appendix:c}.

\begin{figure}[h]
    \centering
    \includegraphics[width=16.5cm]{paper/img/chinese-gold-timeline.png}
    \caption {Timeline of Chinese Gold Story}
    \label{fig:chinesegoldtimeline}
\end{figure}

As it turned out, the original content for the news story was actually a twitter post. What was fascinating was that none of the articles actually attributed that Twitter was the first platform where the content for the story appeared; many of the news outlets did link to the Twitter post, but not once did any of the news sources explicitly say "this content was originally posted on Twitter by a user." It is also important to notice the time delays between when the story was first posted on Twitter, and when it was picked up by mainstream media. The initial twitter post was made on September 24. It took about two days for international news outlets (PowerApple, CrimeRussina, MenaFN, Novinite) to pick up this news story. It took about seven days for mainstream news outlets (RT, Daily Star, Daily Mail, Mirror) to pick up this news articles. It is important to note these time delays as it can be used to categorize bottom-up syndication, which we will define later in this work. 

\subsubsection{Article Feature Analysis}
Besides just looking at how the article traveled through space and time as it was syndicated, we were interested in looking at how the articles' properties changed over time.
\begin{figure}[h]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=7cm]{paper/img/chinese-gold-article-len.png}
  \captionof{figure}{Article Length Over Time}
  \label{chinesegoldarticlelen}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=7cm]{paper/img/chinese-gold-title-len.png}
  \captionof{figure}{Title Length Over Time}
  \label{chinesegoldtitlelen}
\end{minipage}
\end{figure}


From Figures \ref{chinesegoldarticlelen} and \ref{chinesegoldtitlelen}, we can see that the general trend for both the article length and title length was that as the article was syndicated, both features became longer. By actually analyzing the content of the article, it seems as though as each article was syndicated by another news outlet, they made more inferences about the article. For example, the original Twitter post just showed a video, and short description about the video. By the time Daily Mail posted their version of the article, they were making inferences about the official's total net worth, his assets, as well as general claims about anti corruption in China. None of these topics were ever discussed by the original Twitter post. The Daily Mail just assumed these as fact and wrapped everything up into one story.   

\subsection{Case Study: University of Virginia}
Once we found the story about the Chinese gold story, we wanted to see if other similar articles exhibited the same properties and characteristics. We started looking for articles which origin could be traced back to either a social media post, or a local news media outlet. One of the first articles that we identified was the story titled \texit{University of Virginia cancels 21-gun salute from Veterans Day ceremony} on Fox News. 

\subsection{Findings}
We found that

\subsubsection{Different Types of Syndication}
Top-down and bottom-up

\section{Phase II - Semiautonomous Approach }
In the semiautomated approach, we wanted to see if our findings from phase I would still hold true against a larger data set. We automated the process of tracing the propagation path and conducting analysis on the resulting articles. The resulting methodology from phase II is the main contribution of this work.









\section{Future Work}

\section{Discussion and Conclusion}


%References
\newpage

\bibliographystyle{unsrt}  
\bibliography{paper} 


%Appendix
\newpage

\appendix
\section{Initial Dataset Used for Phase I Analysis}
\label{appendix:a}
\begin{center}
 \begin{longtable}{| c | m{10cm} | c |} 
 \hline
 \multicolumn{1}{|c|}{\textbf{Media Outlet}} &
 \multicolumn{1}{c|}{\textbf{Article}} &
 \multicolumn{1}{c|}{\textbf{Comments}}  \\ 
 \hline\hline
 Patribotics & Dear Mr. Putin, Let’s Play Chess & 148 \\ 
 \hline
  Patribotics & Wikileaks is Connected to Russia – Despite Their Claims & 42 \\ 
 \hline
  Patribotics & Planespotting: Michael Cohen’s Amazing Journey & 49 \\ 
 \hline
  Patribotics &Putin’s Hacker, Wikileaks Host Pyotr Chayanov, Hacked America’s Vote System And the DNC & 11 \\ 
 \hline
  Patribotics &Wikileaks Hands “Keys” to Putin’s Russian Hacker – Readers, Leakers Tracked & 19 \\ 
 \hline
 InfoWars & De-Dollarization: Europe Joins The Party
 & 6 \\
 \hline
  InfoWars & Unemployment Falls to Lowest Level Since 1969
 & 13 \\
 \hline
  InfoWars & China Unveils ‘doomsday Bomb’ While U.s. Military Concentrates on “diversity” & 83 \\
 \hline
  InfoWars & ‘no Precedent in Human Experience’: Study Finds Nuclear War Between India and Pakistan Could Leave 125 Million Dead & 6 \\
 \hline
  InfoWars & China Reveals New Photos of Strange Substance From Dark Side of Moon
 & 26 \\
 \hline
  Daily Caller & Iranian Foreign Minister Uses Instagram To Resign & 22 \\
 \hline
 Daily Caller & Israel Holding Early Elections As Bribery Allegations Engulf Netanyahu & 12  \\
 \hline
  Daily Caller & Turkey’s President Arrests More Than 100 People For Connections To Failed 2016 Coup & 4  \\
 \hline
  Daily Caller & Saudi Crown Prince Fires Entertainment Chief Because Of Tightly Clad Female Circus Performers & 4  \\
 \hline
  Daily Caller & Hong Kong Police Unload Live Rounds On Protesters, Shoot 18-Year-Old: Report
 & 23  \\
 \hline
  Daily KOS & How to Support the Hong Kong Protesters & 2 \\
 \hline
  Daily KOS & Who knew? Ukraine-gate is actually a Rick Perry crime spree! & 76 \\
 \hline
  Daily KOS & NYT: Second Ukraine-related whistleblower may soon come forward & 96 \\
 \hline
  Daily KOS & Have we learned nothing about wars in the Middle East? & 119 \\
 \hline
  Daily KOS & Open thread for night owls: 'Itching for a War' with Iran & 93 \\
 \hline
 Daily Mail & Russia is helping China build a new missile attack warning system in 'response' to US plans to deploy missiles in Asia & 44 \\
 \hline
  Daily Mail & British sausage makers claim nation's bangers are under threat from pork shortage in China that has seen prices rise by 45 per cent & 184 \\
 \hline
  Daily Mail & Thousands of pro-democracy activists rally in Hong Kong ahead of four days of protests to overshadow anniversary celebrations in Beijing & 0 \\
 \hline
  Daily Mail & Thirteen and a half tonnes of gold worth up to £520million is found in a corrupt Chinese official's home and £30BILLION in suspected bribe money in his bank account & 451 \\
 \hline
  Daily Mail & 'Most-wanted' Chinese fugitive, 63, hides in a cliff-side cave for 17 YEARS after escaping from prison & 6 \\
 \hline
 The Washington Times & Man pulls gun in road rage incident over Elizabeth Warren sticker, police say & 2  \\
 \hline
  The Washington Times & Man pulls gun in road rage incident over Elizabeth Warren sticker, police say & 5  \\
 \hline
  The Washington Times & Man pulls gun in road rage incident over Elizabeth Warren sticker, police say & 124  \\
 \hline
  The Washington Times & FBI runs Russian-language Facebook ads asking for help neutralizing 'hostile foreign intelligence' & 1  \\
 \hline
  The Washington Times & FBI runs Russian-language Facebook ads asking for help neutralizing 'hostile foreign intelligence' & 0  \\
 \hline
 Mother Jones & It’s No Coincidence That the Top Presidential Candidates Are All So Old & 6  \\
 \hline
  Mother Jones & Columnist at the Center of Ukraine Scandal Joins Fox News & 5  \\
 \hline
  Mother Jones & Microsoft Says Iranian Hackers Are Targeting a 2020 Presidential Campaign & 9  \\
 \hline
 
 \hline
 \multicolumn{1}{|c|}{\textbf{Media Outlet}} &
 \multicolumn{1}{c|}{\textbf{Article}} &
 \multicolumn{1}{c|}{\textbf{Comments}}  \\ 
 \hline\hline
 
 \hline
  Mother Jones & Researchers Assembled over 100 Voting Machines. Hackers Broke Into Every Single One.
 & 7  \\
 \hline
  Mother Jones & The Biden Campaign Is Demanding That TV Execs Stop Booking Guiliani & 69  \\
 \hline
 Reason & Supreme Court Will Finally Hear Arguments Over Federal LGBT Discrimination Protections & 100 \\
 \hline
  Reason & China Banned South Park After the Show Made Fun of Chinese Censorship & 105\\
 \hline
  Reason & The NBA Cares More About Making Money in Mainland China Than Supporting Freedom in Hong Kong & 94 \\
 \hline
  Reason & The U.K. Must Ban Pointy Knives, Says Church of England & 76 \\
 \hline
 Reason & The New York Times Says 'Free Speech Is Killing Us.' But Violent Crime Is Lower Than Ever. & 120 \\ [1ex] 
 \hline
\end{longtable}
\end{center}

\newpage
\section{Media Bias Diagram}
\label{appendix:b}
\begin{figure}[h]
    \centering
    \includegraphics[width=15cm]{paper/img/media-bias.jpg}
    \caption* {Media Bias Diagram}
    \label{fig:mediabias}
\end{figure}

\newpage
\section{Chinese Gold Story Dataset}
\label{appendix:c}
\begin{center}
 \begin{tabular}{| c | m{10cm} | c |} 
 \hline
 \multicolumn{1}{|c|}{\textbf{Media Outlet}} &
 \multicolumn{1}{c|}{\textbf{Article Title}} &
 \multicolumn{1}{c|}{\textbf{Date of Publication}}  \\ 
 \hline\hline
 Twitter & N/A (Twitter post by user @h1300062810) & . 09-24-2019 10:09 \\ 
 \hline
  PowerApple & Secretary of Haikou copied 13.5 tons of cash, booked 268 billion in gold (translated)  & 09-26-2019 08:08 \\ 
 \hline
  CrimeRussia & Chinese official hides 13 tons of gold in basement & 09-26-2019 09:50 \\ 
 \hline
  MenaFN & 13.5 Tons Of Gold Found In Chinese Ex Mayors Basement & 09-26-2019 18:20 \\ 
 \hline
  Novinite & 13 Tonnes of Gold Found in the Basement of Former Chinese Mayor & 09-27-2019 13:49 \\ 
 \hline
 RT & 13.5 TONS of gold found piled in Chinese ex-governor’s home & 10-01-2019 13:37 \\
 \hline
  Daily Star & 13.5 tons of gold and \$37billion cash found during police raid on mayor in China & 10-01-2019 18:21 \\
 \hline
  Daily Mail & Thirteen and a half tonnes of gold worth up to £520million is found in a corrupt Chinese official's home and £30BILLION in suspected bribe money in his bank account & 10-02-2019 04:54 \\
 \hline
  Mirror & Corrupt Chinese official found with £520million worth of gold bullion in home & 10-03-2019 02:01 \\
 \hline
\end{tabular}
\end{center}

\newpage
\section{University of Virginia Story Dataset}
\label{appendix:d}
\begin{center}
 \begin{tabular}{| c | m{10cm} | c |} 
 \hline
 \multicolumn{1}{|c|}{\textbf{Media Outlet}} &
 \multicolumn{1}{c|}{\textbf{Article Title}} &
 \multicolumn{1}{c|}{\textbf{Date of Publication}}  \\ 
 \hline\hline
  The Daily Progress & Opinion/Letter: UVa should rethink Veterans Day decision  & 11-06-2019 09:26 \\ 
 \hline
  WHSV & VA reinstates 21-gun salute on Veterans Day after wide-scale backlash & 11-08-2019 14:11 \\ 
 \hline
  The College Fix & Citing ‘gun violence,’ UVA cancels 21-gun salute portion of Veterans Day ceremony & 11-11-2019 05:05 \\ 
 \hline
  The Christian Perspective & University of Virginia Cancels 21-Gun Salute to Appease Snowflake Students & 11-11-2019 13:15 \\ 
 \hline
 Washington Examiner & University of Virginia ending 21-gun salute over potential 'panic' by students & 11-11-2019 13:20 \\
 \hline
 The Hill & University of Virginia cancels 21-gun salute to veterans over concern it might 'cause a panic' & 11-11-2019 18:41 \\
 \hline
 Fox News & University of Virginia cancels 21-gun salute from Veterans Day ceremony & 11-11-2019 20:42 \\
 \hline
  RT & University of Virginia excoriated for ditching Veterans Day 21-gun salute ‘because gun violence’ & 11-11-2019 21:59\\
 \hline
  Daily Caller & Students Force University Of Virginia To End 21-Gun Salute On Veterans Day & 11-11-2019 22:14 \\
 \hline


\end{tabular}
\end{center}

\end{document}