{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import load\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = load(\"./models/keyword/tfidf_transformer.joblib\")\n",
    "cv = load(\"./models/keyword/CountVector.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test docs into a dataframe and concatenate title and body\n",
    "df_test=pd.read_csv(\"./dataset/meta.csv\")\n",
    "df_test['text'] = df_test['title'] + df_test['content']\n",
    "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=df_test['text'].tolist()\n",
    "docs_title=df_test['title'].tolist()\n",
    "docs_body=df_test['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Video sparks fears Hong Kong protesters being... | Taiwan News\n",
      "\n",
      "=====Body=====\n",
      "\n",
      " TAIPEI (Taiwan News) - A video that surfaced on Monday (Nov. 18) appearing to show Hong Kong protesters being loaded onto a train near the border with China has sparked fears online that they are being sent to a detention center in the communist country.\n",
      "As clashes continued on a university campus between riot police and pro-democracy protesters, a video was posted on Twitter spurring concerns that arrested demonstrators were being illegally extradited to China. At 2:33 p.m. on Monday, Twitter user @Woppa1Woppa posted a video showing handcuffed protesters being forced onto a train and wrote that it was unknown where they were being sent.\n",
      "Below the Tweet, several netizens identified the train as belonging to the East Rail Line of the Mass Transit Railway (MTR) system. Although the detainees' destination is unknown, netizens pointed out that the last two stations are Lo Wu and Lok Ma Chau, which are both border checkpoints into China.\n",
      "Twitter users suggested that the students were from Hong Kong Polytechnic University, which was the scene of fierce clashes between riot police and pro-democracy protesters on Monday. One Twitter user, who goes by the handle @lilisuricate, ominously said that there are no Hong Kong police stations near any of the stops along the train's route to the China border.\n",
      "The youth activist group Demosisto wrote on Twitter that people in North District \"threw objects on the railway track\" to prevent the protesters from being transported to China. Hong Kong police have yet to issue an official statement on the destination of the arrested demonstrators.\n",
      "\n",
      "Arrested protesters are getting transported out on a train. Unknown at this time where they will be sent. Residents and press are heard asking for their names via on9谷#StandWithHongKong #HongKongProtests pic.twitter.com/N2I4MMXu8R - woppa\n",
      "\n",
      "At 12:34 p.m. on Monday, the Facebook group \"Clear Voices from the Island\" (港島你明) uploaded a post which included several photos of apparent protesters allegedly being loaded onto the train. The author of the post then writes that there is a high-resolution photo of a train originating from Hung Hom Station taken at 12:01 p.m. and showing people in handcuffs being led onboard.\n",
      "The post first gives the time 12:23 p.m. and says \"Mong Kok East Station.\" It then states at 12:28 that two vans in the \"upper left [of photo]\" have the license plate numbers VF7046 and AM2837.\n",
      "The author then requests anyone who recognizes the detainees in the photo to contact the page's administrator.\n",
      "Facebook post by Clear Voices from the Island showing photos of the incident:\n",
      "Video showing what appears to be detained protesters being forced onto a train:\n",
      "Twitter post pleading with readers to share the video on social media:\n",
      "\n",
      "HONG KONG POLICE ARRESTED PROTESTERS and CITIZENS. They were TAKEN on the train and NO ONE KNOWS where will they go! PLEASE SAVE THIS VIDEO AND REPOST TO OTHERS SOCIAL MEDIA! OUR KIDS CANT BE DISAPPEARED!#SOSPolyU #SOSHK #HongKongProtesters pic.twitter.com/Prw9jQwDRF - (@jwwaholic)\n",
      "November 18, 2019\n",
      "\n",
      "\n",
      "\n",
      "===Keywords===\n",
      "train 0.454\n",
      "twitter 0.349\n",
      "police 0.314\n",
      "china 0.305\n",
      "video 0.264\n",
      "monday 0.21\n",
      "showing 0.137\n",
      "photo 0.135\n",
      "post 0.135\n",
      "university 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnsd1\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# you only needs to do this once\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=docs_test[2]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "\n",
    "# now print the results\n",
    "print(\"\\n=====Title=====\")\n",
    "print(docs_title[2])\n",
    "print(\"\\n=====Body=====\")\n",
    "print(docs_body[2])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
